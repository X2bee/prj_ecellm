---
base_model: answerdotai/ModernBERT-base
---

# x2bee/KoModernBERT-base-mlm-v03-retry-ckp03
This model is a fine-tuned version of [answerdotai/ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) on [x2bee/Korean_wiki_corpus](https://huggingface.co/datasets/x2bee/Korean_wiki_corpus) and [x2bee/Korean_namuwiki_corpus](https://huggingface.co/datasets/x2bee/Korean_namuwiki_corpus). <br>

### Example Use.

```bash
git clone https://github.com/X2bee/prj_ecellm.git
```

```python
import os
os.chdir("/workspace")
from models.bert_mlm import ModernBertMLM

test_model = ModernBertMLM(model_id="x2bee/KoModernBERT-base-mlm-v03-retry-ckp03")

text = "30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œ[MASK] í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ [MASK] ë‹¹ì‹œ ê¸°ì²´ê°€ [MASK]ì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ [MASK]ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  [MASK]ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤."
result = test_model.modern_bert_convert_with_multiple_masks(text, top_k=5)
result
```

### Output
```
Predicted: ê³µí•­ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ [MASK] ë‹¹ì‹œ ê¸°ì²´ê°€ [MASK]ì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ [MASK]ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  [MASK]ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì‚¬ê³  | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ [MASK]ì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ [MASK]ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  [MASK]ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ë¹„ìƒ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ [MASK]ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  [MASK]ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ìŠ¹ê° | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  [MASK]ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì”í•´ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ [MASK]ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: í›¼ì† | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. [MASK] ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì‚¬ê³  | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ [MASK] ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ë°œìƒ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ [MASK]ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì£¼ì¥ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° [MASK]ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ë‚´ë¶€ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° ë‚´ë¶€ì— ì„¤ì¹˜ëœ [MASK](ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ESP | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° ë‚´ë¶€ì— ì„¤ì¹˜ëœ ESP(ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ [MASK]ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì‚¬ê³  | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° ë‚´ë¶€ì— ì„¤ì¹˜ëœ ESP(ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ ì‚¬ê³ ë¥¼ í‚¤ì› ë‹¤ëŠ” [MASK]ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Predicted: ì£¼ì¥ | Current text: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° ë‚´ë¶€ì— ì„¤ì¹˜ëœ ESP(ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ ì‚¬ê³ ë¥¼ í‚¤ì› ë‹¤ëŠ” ì£¼ì¥ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.

```

### Compare with Real Value
```
Answer: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ëŒ€ì°¸ì‚¬ ë‹¹ì‹œ ê¸°ì²´ê°€ ë™ì²´ì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  í•­ê³µê¸°ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ íŒŒì†ëë‹¤. í”¼í•´ ê·œëª¨ì™€ ì‚¬ê³  ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì˜ë¬¸ì ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° í™œì£¼ë¡œì— ì„¤ì¹˜ëœ ë¡œì»¬ë¼ì´ì €(ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ í”¼í•´ë¥¼ í‚¤ì› ë‹¤ëŠ” ì§€ì ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.
Output: 30ì¼ ì „ë‚¨ ë¬´ì•ˆêµ­ì œê³µí•­ í™œì£¼ë¡œì— ì „ë‚  ë°œìƒí•œ ì œì£¼í•­ê³µ ì‚¬ê³  ë‹¹ì‹œ ê¸°ì²´ê°€ ë¹„ìƒì°©ë¥™í•˜ë©´ì„œ ê°•í•œ ë§ˆì°°ë¡œ ìƒê¸´ í”ì ì´ ë‚¨ì•„ ìˆë‹¤. ì´ ì°¸ì‚¬ë¡œ ìŠ¹ê°ê³¼ ìŠ¹ë¬´ì› 181ëª… ì¤‘ 179ëª…ì´ ìˆ¨ì§€ê³  ì”í•´ëŠ” í˜•ì²´ë¥¼ ì•Œì•„ë³¼ ìˆ˜ ì—†ì´ í›¼ì†ëë‹¤. ì‚¬ê³  ê·œëª¨ì™€ ë°œìƒ ì›ì¸ ë“±ì— ëŒ€í•´ ë‹¤ì–‘í•œ ì£¼ì¥ì´ ì œê¸°ë˜ê³  ìˆëŠ” ê°€ìš´ë° ë‚´ë¶€ì— ì„¤ì¹˜ëœ ESP(ì°©ë¥™ ìœ ë„ ì•ˆì „ì‹œì„¤)ê°€ ì‚¬ê³ ë¥¼ í‚¤ì› ë‹¤ëŠ” ì£¼ì¥ì´ ë‚˜ì˜¤ê³  ìˆë‹¤.

```

# plateer_classifier_ModernBERT_v01
This model is a fine-tuned version of [x2bee/ModernBert_MLM_kotoken_v01](https://huggingface.co/x2bee/ModernBert_MLM_kotoken_v01) on [x2bee/plateer_category_data](https://huggingface.co/datasets/x2bee/plateer_category_data). <br>
It achieves the following results on the evaluation set:
- Loss: 0.3379

### Example Use.
```python
import os
os.chdir("/workspace")
from models.bert_cls import plateer_classifier;

result = plateer_classifier("ê²¨ìš¸ ë“±ì‚°ì—ì„œ ì‚¬ìš©í•  ì˜·")[0]
print(result)

############# result
-----------Category-----------
{'label': 2, 'label_decode': 'ê¸°ëŠ¥ì„±ì˜ë¥˜', 'score': 0.9214227795600891}
{'label': 8, 'label_decode': 'ìŠ¤í¬ì¸ ', 'score': 0.07054771482944489}
{'label': 15, 'label_decode': 'íŒ¨ì…˜/ì˜ë¥˜/ì¡í™”', 'score': 0.0036312134470790625}
```

# CocoRoF/ModernBERT-SimCSE
This is a [sentence-transformers](https://www.SBERT.net) model finetuned from [answerdotai/ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) on the [korean_nli_dataset](https://huggingface.co/datasets/x2bee/Korean_NLI_dataset) dataset. It maps sentences & paragraphs to a 768-dimensional dense vector space and can be used for semantic textual similarity, semantic search, paraphrase mining, text classification, clustering, and more.

## Model Details

### Model Description
- **Model Type:** Sentence Transformer
- **Base model:** [answerdotai/ModernBERT-base](https://huggingface.co/answerdotai/ModernBERT-base) <!-- at revision addb15798678d7f76904915cf8045628d402b3ce -->
- **Maximum Sequence Length:** 512 tokens
- **Output Dimensionality:** 768 dimensions
- **Similarity Function:** Cosine Similarity
<!-- - **Language:** Unknown -->
<!-- - **License:** Unknown -->

### Model Sources

- **Documentation:** [Sentence Transformers Documentation](https://sbert.net)
- **Repository:** [Sentence Transformers on GitHub](https://github.com/UKPLab/sentence-transformers)
- **Hugging Face:** [Sentence Transformers on Hugging Face](https://huggingface.co/models?library=sentence-transformers)

### Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: ModernBertModel 
  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': True, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
  (2): Dense({'in_features': 768, 'out_features': 768, 'bias': True, 'activation_function': 'torch.nn.modules.activation.Tanh'})
)
```

## Usage

### Direct Usage (Sentence Transformers)

First install the Sentence Transformers library:

```bash
pip install -U sentence-transformers
```

Then you can load this model and run inference.
```python
from sentence_transformers import SentenceTransformer

# Download from the ğŸ¤— Hub
model = SentenceTransformer("CocoRoF/ModernBERT-SimCSE")
# Run inference
sentences = [
    'ë²„ìŠ¤ê°€ ë°”ìœ ê¸¸ì„ ë”°ë¼ ìš´ì „í•œë‹¤.',
    'ë…¹ìƒ‰ ë²„ìŠ¤ê°€ ë„ë¡œë¥¼ ë”°ë¼ ë‚´ë ¤ê°„ë‹¤.',
    'ê·¸ ì—¬ìëŠ” ë°ì´íŠ¸í•˜ëŸ¬ ê°€ëŠ” ì¤‘ì´ë‹¤.',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 768]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities.shape)
# [3, 3]
```

### Metrics

#### Semantic Similarity

* Dataset: `sts_dev`
* Evaluated with [<code>EmbeddingSimilarityEvaluator</code>](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html#sentence_transformers.evaluation.EmbeddingSimilarityEvaluator)

| Metric             | Value      |
|:-------------------|:-----------|
| pearson_cosine     | 0.8273     |
| spearman_cosine    | 0.8298     |
| pearson_euclidean  | 0.8112     |
| spearman_euclidean | 0.8214     |
| pearson_manhattan  | 0.8125     |
| spearman_manhattan | 0.8226     |
| pearson_dot        | 0.7648     |
| spearman_dot       | 0.7648     |
| pearson_max        | 0.8273     |
| **spearman_max**   | **0.8298** |