{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/workspace\")\n",
    "from models.bert_mlm import ModernBertMLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "model_name = \"x2bee/KoModernBERT-base-nli-sts-SBERT_v01\"\n",
    "model = SentenceTransformer(model_name)\n",
    "sts_model = ModernBERTsts(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 8192, 'do_lower_case': False}) with Transformer model: ModernBertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : KakaoBrain\n",
      "    Repository : https://github.com/kakaobrain/KorNLUDatasets\n",
      "    References :\n",
      "        - Ham, J., Choe, Y. J., Park, K., Choi, I., & Soh, H. (2020). KorNLI and KorSTS: New Benchmark\n",
      "           Datasets for Korean Natural Language Understanding. arXiv preprint arXiv:2004.03289.\n",
      "           (https://arxiv.org/abs/2004.03289)\n",
      "\n",
      "    This is the dataset repository for our paper\n",
      "    \"KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding.\"\n",
      "    (https://arxiv.org/abs/2004.03289)\n",
      "    We introduce KorNLI and KorSTS, which are NLI and STS datasets in Korean.\n",
      "\n",
      "    # License\n",
      "    Creative Commons Attribution-ShareAlike license (CC BY-SA 4.0)\n",
      "    Details in https://creativecommons.org/licenses/by-sa/4.0/\n",
      "\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-train.tsv\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-dev.tsv\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-test.tsv\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "corpus = Korpora.load(\"korsts\", root_dir=\"/workspace/Korpora\")\n",
    "labels = [(float(label)) for label in corpus.test.labels]\n",
    "\n",
    "# dev_evaluator = EmbeddingSimilarityEvaluator(\n",
    "#     sentences1=corpus.test.texts,\n",
    "#     sentences2=corpus.test.pairs,\n",
    "#     scores=labels,\n",
    "#     similarity_fn_names=['cosine', 'euclidean', 'manhattan', 'dot'],\n",
    "#     name=\"sts_dev\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus.train.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = ['한 남자가 음식을 먹는다.',\n",
    "              '한 남자가 빵 한 조각을 먹는다.',\n",
    "              '그 여자가 아이를 돌본다.',\n",
    "              '한 남자가 말을 탄다.',\n",
    "              '한 여자가 바이올린을 연주한다.',\n",
    "              '두 남자가 수레를 숲 속으로 밀었다.',\n",
    "              '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    "              '원숭이 한 마리가 드럼을 연주한다.',\n",
    "              '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "sentences2 = ['한 남자가 파스타를 먹는다.',\n",
    "               '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "               '치타가 들판을 가로 질러 먹이를 쫓는다.']\n",
    "\n",
    "# print(\"roberta_sts\")\n",
    "# roberta_sts(sentences1, sentences2)\n",
    "print(\"modern_bert_sts\")\n",
    "sts_model.process(sentences2, sentences1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = ['산행을 위한 용품']\n",
    "sentences2 = ['한방 치료에 좋은 물건',\n",
    "              '등산용 스틱',\n",
    "              '겨울철 패딩',\n",
    "              '겨울 장판']\n",
    "print(\"roberta_sts\")\n",
    "roberta_sts(sentences1, sentences2)\n",
    "print(\"modern_bert_sts\")\n",
    "sts_model.process(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(\u001b[43msentences\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(embeddings\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# [3, 768]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Get the similarity scores for the embeddings\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 768]\n",
    "\n",
    "# Get the similarity scores for the embeddings\n",
    "similarities = model.similarity(embeddings, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in corpus.test:\n",
    "    sentence1 = item.text\n",
    "    sentence2 = item.pair\n",
    "    score = (item.label / 5)\n",
    "    print(sentence1, sentence2, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KorSTSExample(text='한 소녀가 머리를 스타일링하고 있다.', pair='한 소녀가 머리를 빗고 있다.', label=2.5, genre='main-captions', filename='MSRvid', year='2012test')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertForMaskedLM is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n"
     ]
    }
   ],
   "source": [
    "mbm = ModernBertMLM(model_id=\"klue/roberta-base\", subfolder=\"last-checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 공항 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 [MASK] 당시 기체가 [MASK]착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 [MASK]과 승무원 181명 중 179명이 숨지고 [MASK]는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 사고 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 [MASK]착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 [MASK]과 승무원 181명 중 179명이 숨지고 [MASK]는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 비상 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 [MASK]과 승무원 181명 중 179명이 숨지고 [MASK]는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 승객 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 [MASK]는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 기체 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 전소 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 사고 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 사고 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 의혹 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 건물 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 건물에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: ITS | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 건물에 설치된 ITS(착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 사고 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 건물에 설치된 ITS(착륙 유도 안전시설)가 사고를 키웠다는 [MASK]이 나오고 있다.\n",
      "Predicted: 지적 | Current text: 30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 건물에 설치된 ITS(착륙 유도 안전시설)가 사고를 키웠다는 지적이 나오고 있다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'30일 전남 무안국제공항 활주로에 전날 발생한 제주항공 사고 당시 기체가 비상착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 승객과 승무원 181명 중 179명이 숨지고 기체는 형체를 알아볼 수 없이 전소됐다. 사고 규모와 사고 원인 등에 대해 다양한 의혹이 제기되고 있는 가운데 건물에 설치된 ITS(착륙 유도 안전시설)가 사고를 키웠다는 지적이 나오고 있다.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"30일 전남 무안국제[MASK] 활주로에 전날 발생한 제주항공 [MASK] 당시 기체가 [MASK]착륙하면서 강한 마찰로 생긴 흔적이 남아 있다. 이 참사로 [MASK]과 승무원 181명 중 179명이 숨지고 [MASK]는 형체를 알아볼 수 없이 [MASK]됐다. [MASK] 규모와 [MASK] 원인 등에 대해 다양한 [MASK]이 제기되고 있는 가운데 [MASK]에 설치된 [MASK](착륙 유도 안전시설)가 [MASK]를 키웠다는 [MASK]이 나오고 있다.\"\n",
    "\n",
    "result = mbm.modern_bert_convert_with_multiple_masks(text, top_k=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 아름 | Current text: 여전히 아름 [MASK] [MASK] 다이아몬드입니다.\n",
      "Predicted: 다운 | Current text: 여전히 아름 다운 [MASK] 다이아몬드입니다.\n",
      "Predicted: 다이아몬드 | Current text: 여전히 아름 다운 다이아몬드 다이아몬드입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'여전히 아름 다운 다이아몬드 다이아몬드입니다.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"여전히 [MASK] [MASK] [MASK] 다이아몬드입니다.\"\n",
    "\n",
    "result = mbm.modern_bert_convert_with_multiple_masks(text, top_k=5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 합니다 | Current text: I Don't Think 합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I Don't Think 합니다.\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I Don't Think [MASK].\"\n",
    "\n",
    "result = mbm.modern_bert_convert_with_multiple_masks(text, top_k=3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Paris | Current text: The capital city of Paris is Paris.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital city of Paris is Paris.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The capital city of [MASK] is Paris.\"\n",
    "\n",
    "result = mbm.modern_bert_convert_with_multiple_masks(text, top_k=2)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"산행에서 사용할만한 물건을 추천해 줘\"\n",
    "# sentences = [\n",
    "#     \"플래티어 - 등산화\",\n",
    "#     \"야외용 식기\",\n",
    "#     \"겨울철 난방 보조\",\n",
    "#     \"산행은 몸에 해롭다\",\n",
    "#     \"겨울철 머리띠\",\n",
    "#     \"2025년 산행 달력\"\n",
    "# ]\n",
    "\n",
    "query = \"집에서 쓸 게이밍용 컴퓨터가 필요한데\"\n",
    "sentences = [\n",
    "    \"최신 무소음 청축 키보드\",\n",
    "    \"무선 마우스\",\n",
    "    \"인텔코어 I9 LG 그램\",\n",
    "    \"학생용 노트북\",\n",
    "    \"교육용 최신 노트북\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"투명한 에어 프라이어\"\n",
    "sentences = request_item(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"chunk_02chunk_03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chunk_02chunk_03']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences.append(\"투명한 에어프라이어 고무 탭\")\n",
    "# sentences.append(\"불투명한 에어프라이어 베이킹트레이\")\n",
    "sentences.append(\"투명 에어프라이어형 오븐\")\n",
    "sentences.append(\"투명 에어프라이어 그림\")\n",
    "sentences.append(\"투명 에어프라이어 모양 장난감\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 겨울철 사용할만한 물건\n",
      "\n",
      "Sentences sorted by similarity:\n",
      "0.5669 - 휴대용 건조기 미니 의류 건조기 1인 건조기 옷 건조기 진드기 제거용 다기능 의류 마이크로 송풍기 건조기 휴대용 젖은 담요 건조 신발 겨울용 가정용 (12072.07)\n",
      "0.5667 - 온열조끼 골프 등산 온도조절 남성 및 여성용 스마트 난방 21 개 지역 재킷 야외 유연한 보온 의류 따뜻한 겨울 하이킹 낚시 (10001.00)\n",
      "0.5526 - 온열조끼 골프 등산 온도조절 보온 의류 난방 여행용 남성 겨울 코트 따뜻한 탄소 섬유 폴리에스테르 70005000200 (10001.00)\n",
      "0.5442 - 남자 니트 남성 머슬핏 카라티 남성용 겨울 플리스 가디건 두꺼운 후드 긴 스웨터 코트 따뜻한 재킷 캐주얼 외투 의류 (10001.00)\n",
      "0.5381 - 온열조끼 골프 등산 온도조절 남성 겨울 넥 재킷 여성 의류 야외 유연한 하이킹 8 개 영역 (10001.00)\n",
      "0.5320 - 오버롤보드복 남성 스노보드 멜빵바지 의류 겨울 슬림 (10001.00)\n",
      "0.5317 - lovesol YKYWBIKE 겨울 자켓 열 양털 남자 사이클링 긴 소매 자전거 의류 블랙 재킷 (10001.00)\n",
      "0.5297 - 고양이 소형견용 따뜻한 양털 대형 개 재킷 하네스가 달린 방수 애완 동물 코트 치와와 의류 강아지 코스튬 겨울 (10001.00)\n",
      "0.5139 - 대비 트림 라펠 코트 우아한 롱슬리브 랩 타이 허리 롱라인 코트 가을 & 겨울 여성 의류 (10001.00)\n",
      "0.5079 - 발열조끼 온열조끼 온도조절 남성용 겨울 따뜻한 후드 민소매 재킷 슬림핏 겉옷 캐주얼 두꺼운 파카 모자 포함 남성 의류 (10001.00)\n",
      "0.5030 - 발열조끼 온열조끼 온도조절 2024 겨울 남성용 민소매 후드 재킷 캐주얼 따뜻한 코트 남성 면 패딩 의류 오버사이즈 6 (10001.00)\n",
      "0.5003 - 가을과 겨울 새로운 여성 골프 재킷 여성 골프 의류 패션 스웨터 폴로 칼라 얇은 코트 여성의 여름 가짜 투피스 스플 라이스 반팔 티셔츠 (10001.00)\n",
      "0.4990 - 여성용 가을 겨울 5컬러 골덴 밴딩 스판 조거 팬츠 코듀로이 츄리닝 트레이닝 바지 PN0472루즈핏 오버핏 여성의류 빅사이즈 (10001.00)\n",
      "0.4990 - 여성용 가을 겨울 니트 후드집업 와이드 일자 통 바지 세트 츄리닝 트레이닝 투피스 꾸안꾸 셋업 PST0248루즈핏 오버핏 여성의류 빅사이즈 (10001.00)\n",
      "0.4976 - 가을과 겨울 여성 골프 재킷 여성 골프 의류 플러스 벨벳 패딩 스웨터 여성의 겨울 느슨한 캐주얼 패션 재킷 패션 골프 재킷 가을과 겨울 새로운 (13661.25)\n",
      "0.4974 - 더블브레스티드 래펠 칼라 오버코트 우아한 롱슬리브 미디엄 길이 울 블렌드 아우터웨어 가을 & 겨울 여성 의류 (10001.00)\n",
      "0.4960 - 트위드셋업 우아한 여성용 세트 복장 상의 투피스 정장 의류 여성 재킷 매칭 겨울 파티 스커트 자카드 코트 (10001.00)\n",
      "0.4931 - 발열조끼 온열조끼 온도조절 남성용 민소매 재킷 남성 코튼 패딩 코트 스탠드 칼라 따뜻한 의류 5 겨울 패션 (10001.00)\n",
      "0.4887 - 드래곤볼 티셔츠 반다이 태양 오공 만화 플란넬 목욕 가운 가을 및 겨울 따뜻한 잠옷 남녀 가정 의류 (10001.00)\n",
      "0.4865 - 가을/겨울 새로운 여성 골프 의류 여성 골프 재킷 패션 스웨터 코트 흑백 스웨터 여성용 터틀넥 코트 기질 지퍼 카디건 (10001.00)\n",
      "0.4826 - 더블브레스티드 트렌치 라펠 코트 우아한 솔리드 롱슬리브 스플릿 헴 벨트 롱라인 코트 가을 & 겨울 여성 의류 (10001.00)\n",
      "0.4794 - 빅사이즈 니트 후드 모직 코트 여성 가디건 루즈핏 코트 가을 겨울 자켓 여성의류 D88U (10001.00)\n",
      "0.4747 - 가을 겨울 남성여름명상복 린넨 인도 수양 수련 단련 호흡 의상 기도복 요가 의류 2023 (10001.00)\n",
      "0.4694 - 쁘니걸 기모오버후드집업 빅사이즈 여성의류 루즈핏후드집업 롱후드집업 겨울기모집업 후드집업 (10001.00)\n",
      "0.4668 - 여성 귀여운 지퍼 후드 산리오 헬로 키티 패턴 맨투맨 2024 스트릿웨어 의류 가을 겨울 (10001.00)\n",
      "0.4625 - 레이스 피로연 이브닝 봄 빈티지 격자 무늬 코튼 린넨 캐주얼 드레스 여성용 긴팔 루즈핏 가을 겨울 패션 의류 (10001.00)\n",
      "0.4479 - 임산부 겨울 원피스 쪼끼 드레스 만삭 출산 스웨터 임부 하객 의류 임신 루즈핏 니트 긴팔 (10001.00)\n",
      "0.4445 - 임산부 겨울 원피스 브이넥 드레스 의류 임신 하객 스웨터 스커트 촬영 패션 캐주얼 루즈핏 (10001.00)\n",
      "0.4252 - 꽃 자수 스웨터 조끼 가을 & 겨울 캐주얼 크루넥 스웨터 조끼 여성 의류GPXXCY0624123 (10001.00)\n",
      "0.3867 - 일자 분배기 / 직선 분배기 / 온수 호스 다이렉트 연결 분배기 / 온수 매트 호스 연결 부품 / H자 / 1자 (12072.07)\n"
     ]
    }
   ],
   "source": [
    "results = get_sorted_sentences_by_similarity(query, sentences)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nSentences sorted by similarity:\")\n",
    "for sentence, similarity in results:\n",
    "    print(f\"{similarity:.4f} - {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 투명한 에어 프라이어\n",
      "\n",
      "Sentences sorted by similarity:\n",
      "0.4006 - 투명 에어프라이어 디지털 YD-55K07B \n",
      "0.2854 - [스벤] 투명에어프라이어 SAF-6500T \n",
      "0.2715 - 스벤 투명에어프라이어 SAF6500T \n",
      "0.0252 - 투명 에어프라이어 그림\n",
      "0.0051 - 투명 에어프라이어 모양 장난감\n",
      "0.0030 - 에어후라이기 에어프라이 오븐 홈베이커리 소형 투명에어프라이어 가정용 글라스 \n",
      "0.0026 - 투명한 에어프라이어 고무 탭\n",
      "0.0020 - 투명 에어프라이어형 오븐\n",
      "0.0016 - 가정용튀김기 미니튀김기 튀김냄비 투명 비주얼 에어 프라이어 지능형 스팀 및 베이킹 통합 다기능 턴오버 없음 \n",
      "0.0010 - 에어후라이기 에어프라이 글라스 투명에어프라이어 오븐 가정용 \n",
      "0.0009 - 유리에어프라이어 유리용기 보이는프라이어 유리 가시 에어 프라이어 기름 연기 없음 가정용 다기능 광파 화로프라이드 \n",
      "0.0006 - 가정용튀김기 미니튀김기 튀김냄비 투명 시각화 전자동 에어 프라이어 다기능 전기 딥 \n",
      "0.0003 - 투명 에어프라이어 악세서리\n",
      "0.0001 - 스텐에어프라이어 올스텐에어프라이어 가정용 불투명 전기 프라이어 가전제품 휴대용 에어 무연 오븐 라거 용량 \n",
      "0.0000 - 튀김기 소형 미니 컴팩트 튀김냄비 전기 프라이어 오븐 제품 에어 불투명한 무연 용량 휴대용 가전 \n",
      "0.0000 - 불투명한 에어프라이어\n",
      "0.0000 - Ninja Foodi Smart XL FG551용 에어 프라이어 액세서리 재사용 가능한 라이너 에어 프라이어 레시피 북 포함 닌자 푸디용 내열성 매트 식품 안전 간편한 세 \n",
      "0.0000 - 에어프렌드 에어프라이어 전용 용기 대형 19cm, 그레이, 1개 \n",
      "0.0000 - 에어프렌드 에어프라이어 전용 용기 대형 19cm, 바이올렛, 1개 \n",
      "0.0000 - 불투명한 에어프라이어 베이킹트레이\n",
      "0.0000 - 닌자 푸디 스마트 XL 그릴 FG551용 에어 프라이어 재사용 가능한 라이너 액세서리 크리스퍼 바스켓만 해당 에어 프라이어 레시피 북이 있는 논스틱 매트 에어프라이어 액세서 \n",
      "0.0000 - HAHAKU Ninja Foodi DZ401 듀얼 바스켓 에어 프라이어 액세서리용 에어 프라이어 랙 304 스테인리스 스틸 다층 건조기 랙 집게와 장갑 포함 \n",
      "0.0000 - 해외직구 NETILGEN 에어프라이어 오븐 먼지 커버손잡이와 포켓 먼지 방지 청소가 간편한 에어프라이어 커버 가전제품 커버 에어프라이어 액세서리 브라운플라워 \n",
      "0.0000 - [해외직구] MG One 박스 안의 에어 프라이어 실리콘 라이너 2팩 - 에어 프라이어 라이너 재사용 가능 - 쉬운 청소 에어 프라이어 액세서리 - 요리를 위한 실리콘 주방 필수품 \n",
      "0.0000 - 해외직구 DASH DFAF450UP1 에어 프라이어 디럭스 액세서리 번들 \n",
      "0.0000 - 재사용 가능한 에어프라이어 팬 라이너 액세서리 실리콘 에어 프라이어 오븐 베이킹 트레이 피자 치킨 에어프라이어 붙지 않는 실리콘 몰드 \n",
      "0.0000 - YQL YQL 닌자 SL401 더블 스택 2 바스켓 에어 프라이어용 실리콘 에어 프라이어 라이너 Ninja DoubleStack XL 에어 프라이어 액세서리 재사용 가능한 직사각 \n",
      "0.0000 - YQL YQL 닌자 SL401 더블 스택 2 바스켓 에어 프라이어용 실리콘 에어 프라이어 라이너 Ninja DoubleStack XL 에어 프라이어 액세서리 재사용 가능한 직사각 \n",
      "0.0000 - COSORI 12in 1 에어프라이어 토스터 오븐 콤보 로티세리 컨벡션 조리대 베이크 브로일러 로스트 탈수 134 레시피 4개 액세서리 32QT 실버 스테인리스 스틸 \n",
      "0.0000 - 에어프라이어 용기 실리콘 전자레인지 사각 R002-O, 01.직사각 용기 ..., 1개 \n",
      "0.0000 - 휴대용 미니 에어프라이어 에어프라이기 캠핑 야외 실리콘 모양 바구니 트레이 세트 원형 그릴 랙 액세서리 재사용 가능한 접이식 Bpa 프리 몰드 라이너 \n",
      "0.0000 - 휴대용 미니 에어프라이어 에어프라이기 캠핑 야외 실리콘 에어 프라이어 라이너 패드 사각형 재사용 가능 냄비 트레이 내열성 베이킹 오븐 액세서리 \n",
      "0.0000 - 오븐용 바베큐 에어 프라이어 로티세리 에어프라이어 로스트 치킨 침 내구성 로스터 포크 바베큐 그릴 도구 액세서리 \n",
      "0.0000 - 16 5cm 에어 프라이어 오븐 베이킹 트레이 프라이드 치킨 바구니 매트 에어 프라이어 실리콘 포트 교체용 그릴 팬 액세서리 에어프라이어 오븐 베이킹 트레이 \n",
      "0.0000 - 16 5cm 에어 프라이어 오븐 베이킹 트레이 프라이드 치킨 바구니 매트 에어 프라이어 실리콘 포트 교체용 그릴 팬 액세서리 에어프라이어 오븐 베이킹 트레이 \n",
      "0.0000 - 에어 프라이어 오븐 식기 세척기 안전 그릴 팬 플레이트를위한 교체 요리판 메쉬 요리 랙 에어 프라이어 액세서리 \n",
      "0.0000 - 오븐토스터기 토스트기 빵굽는기계 가정용 대용량 빵 베이킹 오븐 자동 토스터 피자 베이커리 전기 에어 프라이어 주방 액세서리 \n"
     ]
    }
   ],
   "source": [
    "results = calculate_similarity(query, sentences)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Query:\", query)\n",
    "print(\"\\nSentences sorted by similarity:\")\n",
    "for sentence, similarity in results:\n",
    "    print(f\"{similarity:.4f} - {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('해피쇼핑 기모 롱 목토시 겨울 방한용품 레져 스포츠 마스크 2개세트 남녀공용 (10001.00)', 0.121291496),\n",
       " ('발열조끼 온열조끼 온도조절 남성용 겨울 따뜻한 후드 민소매 재킷 슬림핏 겉옷 캐주얼 두꺼운 파카 모자 포함 남성 의류 (10001.00)',\n",
       "  0.08920554),\n",
       " ('기모 USB 발열바지 여성 usb발열 따뜻한 겨울방한용품 겨울방한복 겨울바지 USB발열용품 방한바지 남성 (10001.00)',\n",
       "  0.07264909),\n",
       " ('무스탕 따뜻한옷 양털 여성무스탕 겨울옷 가죽 남성무스탕 (10001.00)', 0.07090299),\n",
       " ('겨울 방한 내복 보온 내의 여성의 열 속옷 남성 옷 원활한 두꺼운 더블 레이어 따뜻한 (10001.00)', 0.051753316),\n",
       " ('겨울 따뜻한 남성 밍크 수면바지(MS) 10종 잠옷 바지 남자 파자마 홈웨어 (10001.00)', 0.049196392),\n",
       " ('여성용 따뜻한 램스울 코트 패딩 코튼 겉옷 스탠드 칼라 크롭 재킷 여성 패션 겨울 (10001.00)', 0.048514247),\n",
       " ('발열조끼 온열조끼 온도조절 2024 남성용 두꺼운 따뜻한 면 후드 겉옷 민소매 재킷 캐주얼 남성 여성 상의 가을 겨울 (10001.00)',\n",
       "  0.048181634),\n",
       " ('다이어트복대 기모복대 따뜻한복대 허리보정속옷 배보온 블랙 (10001.00)', 0.048010055),\n",
       " ('아웃도어자켓 남성용 겨울 방수 후드 자켓 바지 캠핑 하이킹 사냥 바람막이 탄성 소프트쉘 따뜻한 옷 (10001.00)',\n",
       "  0.04717085),\n",
       " ('메밀꽃피는날 남녀공용 효 옷고름 누빔 조끼 생활한복 누비 겨울 따뜻한 (10001.00)', 0.04472518),\n",
       " ('402290 1개 여성 미니멀리스트 솔리드 컬러 두꺼운 플란넬 루즈 가운 따뜻한 옷깃 홈웨어 가을 겨울용 핑크 (10001.00)',\n",
       "  0.04254977),\n",
       " ('무스탕 여성무스탕 겨울옷 가죽 양털 따뜻한옷 남성무스탕 (10001.00)', 0.035446662),\n",
       " ('허밍퍼플 여성용 2788-JD 후레아 체크 롱 SK 빅사이즈 모직 겨울 따뜻한 스커트 치마 미시 마담 엄마옷 여성의류 (10001.00)',\n",
       "  0.03045255),\n",
       " ('르엠마 스카프 방한용품 여자목도리 여성머플러 가을머플러 겨울머플러 겨울목도리 가을목도리 여성 머플러 81219(14) (10001.00)',\n",
       "  0.027199158),\n",
       " ('여성용 겨울 방한 내의 Flarixa 원활한 열 속옷 양면 양털 슬리밍 보온병 따뜻한 란제리 흰색 브래지어 옷 (10001.00)',\n",
       "  0.025131756),\n",
       " ('르엠마 [2개 기획상품] 스카프 방한용품 여자목도리 여성머플러 가을머플러 겨울머플러 겨울목도리 가을목도리 넥워머 니트머플러 여성 머플러 81203(6) (10001.00)',\n",
       "  0.024828682),\n",
       " ('드래곤볼 티셔츠 반다이 태양 오공 만화 플란넬 목욕 가운 가을 및 겨울 따뜻한 잠옷 남녀 가정 의류 (10001.00)',\n",
       "  0.024226364),\n",
       " ('커플 아이템 따뜻한잠옷 귀여운수면바지 수면바지 바지 남성 여성 (10001.00)', 0.022897918),\n",
       " ('[맨즈북] 따뜻한 기모안감 남자 빅로고 후드티셔츠 오버핏 대학생 겨울옷 상의 (10001.00)', 0.017800504),\n",
       " ('이월스키복 스키복 자켓 상의 2022 겨울 까마귀 점프 슈트 눈 여성 스포츠 원피스 방한복 여성 복장 방수 스노우 보드 여성 작업복 따뜻한 옷 (10001.00)',\n",
       "  0.016629986),\n",
       " ('Sanrio hellokitty 여성용 3 레이어 퀼트 잠옷 가을 겨울 플러스 벨벳 두꺼운 따뜻한 코튼 자켓 귀여운 가정 의류 (10001.00)',\n",
       "  0.013424301),\n",
       " ('[오는정패션] 할머니가디건 카디건 할머니 니트 따뜻한 겨울옷 꽃무늬 핑크 보라 블루 선물용 실내복요양원 (10001.00)',\n",
       "  0.008850408),\n",
       " ('동물잠옷 상어 캠핑 입는담요 침낭 따뜻한 귀여운 특이한 낮잠 (10001.00)', 0.0055781035),\n",
       " ('권투하는강아지 겨울 점프 슈트 개 작은 개를 위한 따뜻한 방수 옷 두꺼운 다운 코트 의상 치와와 불독 애완 동물 용품 (20001.00)',\n",
       "  0.0042018727),\n",
       " ('권투하는강아지 겨울 점프 슈트 개 작은 개를 위한 따뜻한 방수 옷 두꺼운 다운 코트 의상 치와와 불독 애완 동물 용품 (20001.00)',\n",
       "  0.0042018727),\n",
       " ('할로윈 따뜻한 강아지 겨울옷 귀여운 과일견 코트 후디 플리스 애완견 의상 프렌치 불독 치와와 로파 파라 페로 오렌지M (10001.00)',\n",
       "  0.0021060514),\n",
       " ('미니 건조기 휴대용 접이식 전기 의류 미니 여행용 빠른 건조 따뜻한 공기 아기 옷 옷장 보관 캐비닛 (10001.00)',\n",
       "  0.0013517977),\n",
       " ('휴대용 빨래 건조기 전기 의류 건조기 미니 여행용 접이식 따뜻한 공기 아기 옷 히터 행어 세탁 랙 900W (10001.00)',\n",
       "  0.0009449497),\n",
       " ('할로윈 옵션 강아지 고양이 상어 의상 웃긴 펫 크리스마스 코스프레 드레스 후디 따뜻한 옷 M (10001.00)',\n",
       "  0.0005764947)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3169)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "logits = torch.tensor([\n",
    "    [2.5, 0.3, -1.2, -0.5, 0.7],   # Batch 1\n",
    "    [1.0, -0.2, 0.5, -0.8, -1.0],  # Batch 2\n",
    "    [-0.5, 2.0, -1.5, 0.0, 0.3]    # Batch 3\n",
    "])\n",
    "\n",
    "# target_label: (batch_size=3)\n",
    "target_label = torch.tensor([0, 0, 0])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss = loss_fn(logits, target_label)\n",
    "print(loss)  # 첫 번째 샘플이 높게 예측될수록 손실이 감소\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n",
      "    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n",
      "\n",
      "    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n",
      "    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n",
      "    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n",
      "\n",
      "    # Description\n",
      "    Author : KakaoBrain\n",
      "    Repository : https://github.com/kakaobrain/KorNLUDatasets\n",
      "    References :\n",
      "        - Ham, J., Choe, Y. J., Park, K., Choi, I., & Soh, H. (2020). KorNLI and KorSTS: New Benchmark\n",
      "           Datasets for Korean Natural Language Understanding. arXiv preprint arXiv:2004.03289.\n",
      "           (https://arxiv.org/abs/2004.03289)\n",
      "\n",
      "    This is the dataset repository for our paper\n",
      "    \"KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding.\"\n",
      "    (https://arxiv.org/abs/2004.03289)\n",
      "    We introduce KorNLI and KorSTS, which are NLI and STS datasets in Korean.\n",
      "\n",
      "    # License\n",
      "    Creative Commons Attribution-ShareAlike license (CC BY-SA 4.0)\n",
      "    Details in https://creativecommons.org/licenses/by-sa/4.0/\n",
      "\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-train.tsv\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-dev.tsv\n",
      "[Korpora] Corpus `korsts` is already installed at /workspace/Korpora/korsts/sts-test.tsv\n"
     ]
    }
   ],
   "source": [
    "from Korpora import Korpora\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "corpus = Korpora.load(\"korsts\", root_dir=\"/workspace/Korpora\")\n",
    "labels = [(float(label)/5) for label in corpus.test.labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def cal_score(a, b):\n",
    "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
    "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100\n",
    "\n",
    "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta-multitask') \n",
    "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta-multitask')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[45.2584]], grad_fn=<MulBackward0>) tensor([[43.6613]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sentences = ['제대로 작동하는지 전혀 모르겠는 녀석',\n",
    "             '작동법을 이해하려고 노력하는 녀석',\n",
    "             '작동법을 이해하는 녀석']\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "score01 = cal_score(embeddings[0][0], embeddings[1][0])\n",
    "score02 = cal_score(embeddings[0][0], embeddings[2][0])\n",
    "print(score01, score02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_model():\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def encode(self, sentences, **kwargs):\n",
    "        inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        embeddings, _ = model(**inputs, return_dict=False)\n",
    "        \n",
    "        return embeddings[:, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel = test_model(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mmodel.encode(\"아니 뭐가 나오는거에요\")\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances, paired_euclidean_distances, paired_manhattan_distances\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(sen1, sen2, lab):\n",
    "    embeddings1 = mmodel.encode(sen1).detach().numpy().squeeze(1)\n",
    "    print(embeddings1.shape)\n",
    "    embeddings2 = mmodel.encode(sen2).detach().numpy().squeeze(1)\n",
    "    labels = lab\n",
    "    print(embeddings2.shape)\n",
    "    cosine_scores = 1 - paired_cosine_distances(embeddings1, embeddings2)\n",
    "    print(cosine_scores)\n",
    "    print(labels)\n",
    "    manhattan_distances = -paired_manhattan_distances(embeddings1, embeddings2)\n",
    "    euclidean_distances = -paired_euclidean_distances(embeddings1, embeddings2)\n",
    "    dot_products = [np.dot(emb1, emb2) for emb1, emb2 in zip(embeddings1, embeddings2)]\n",
    "\n",
    "    eval_pearson_cosine = pearsonr(labels, cosine_scores)\n",
    "    eval_spearman_cosine = spearmanr(labels, cosine_scores)\n",
    "\n",
    "    eval_pearson_manhattan = pearsonr(labels, manhattan_distances)\n",
    "    eval_spearman_manhattan = spearmanr(labels, manhattan_distances)\n",
    "\n",
    "    eval_pearson_euclidean = pearsonr(labels, euclidean_distances)\n",
    "    eval_spearman_euclidean = spearmanr(labels, euclidean_distances)\n",
    "\n",
    "    eval_pearson_dot, _ = pearsonr(labels, dot_products)\n",
    "    eval_spearman_dot, _ = spearmanr(labels, dot_products)\n",
    "    \n",
    "    return {\n",
    "        \"pearson_cosine\": eval_pearson_cosine,\n",
    "        \"spearman_cosine\": eval_spearman_cosine,\n",
    "        \"pearson_manhattan\": eval_pearson_manhattan,\n",
    "        \"spearman_manhattan\": eval_spearman_manhattan,\n",
    "        \"pearson_euclidean\": eval_pearson_euclidean,\n",
    "        \"spearman_euclidean\": eval_spearman_euclidean,\n",
    "        \"pearson_dot\": eval_pearson_dot,\n",
    "        \"spearman_dot\": eval_spearman_dot,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 768)\n",
      "(30, 768)\n",
      "[0.8633722  0.7684556  0.9280379  1.         0.50636923 0.546602\n",
      " 0.8831411  0.38113976 0.64256126 0.47401762 0.47401762 0.9887142\n",
      " 0.15946877 0.9068202  0.5130687  0.42496443 0.9011234  0.83642864\n",
      " 0.7242777  0.36149287 0.5320018  0.29382098 0.97001725 0.9536537\n",
      " 0.26765144 0.68964326 0.08408737 0.6127579  0.17599219 0.7699957 ]\n",
      "[0.5, 0.72, 1.0, 0.8400000000000001, 0.3, 0.36, 0.7, 0.44000000000000006, 0.44000000000000006, 0.3428, 0.3428, 1.0, 0.12, 0.8800000000000001, 0.4, 0.36, 0.8800000000000001, 0.72, 0.72, 0.24, 0.48, 0.04, 0.8400000000000001, 0.8800000000000001, 0.45, 0.4, 0.15, 0.44000000000000006, 0.16, 0.44000000000000006]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': PearsonRResult(statistic=0.8978460541561896, pvalue=1.7502053161219838e-11),\n",
       " 'spearman_cosine': SignificanceResult(statistic=0.8878010219210499, pvalue=6.103622258783296e-11),\n",
       " 'pearson_manhattan': PearsonRResult(statistic=0.9081268463667417, pvalue=4.2310828368385025e-12),\n",
       " 'spearman_manhattan': SignificanceResult(statistic=0.883339710253105, pvalue=1.0239749778400525e-10),\n",
       " 'pearson_euclidean': PearsonRResult(statistic=0.9072798916259901, pvalue=4.785418514818857e-12),\n",
       " 'spearman_euclidean': SignificanceResult(statistic=0.8878010219210499, pvalue=6.103622258783296e-11),\n",
       " 'pearson_dot': 0.8972431438696812,\n",
       " 'spearman_dot': 0.8889163498380361}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(corpus.test.texts[:30], corpus.test.pairs[:30], labels[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
